---
title: "Dungeness River Winter Steelhead SONAR-based Escapement Estimates"
subtitle: "2019 - 2023"
author:
  - Bethany Craig:
      email: Bethany.Craig@dfw.wa.gov
      institute: [wdfw]
      correspondence: true
  - Kevin See:
      email: Kevin.See@dfw.wa.gov
      institute: [wdfw]
      correspondence: false
  - Joseph Anderson:
      email: Joseph.Anderson@dfw.wa.gov
      institute: [wdfw]
      correspondence: false
institute:
  - wdfw: Washington Department of Fish & Wildlife
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
    wdfwTemplates::wdfw_html_format2:
      fig_caption: yes
      fig_height: 4
      fig_width: 6
      toc: yes
      toc_depth: 3
      toc_float:
        collapsed: yes
        smooth_scroll: yes
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
    bookdown::pdf_document2:
      keep_tex: FALSE
      fig_caption: yes
      fig_height: 5
      fig_width: 6
      toc: yes
      includes:
        in_header: ../templates/header_WDFW.tex
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks2.lua
      - --lua-filter=../templates/pagebreak.lua
    bookdown::word_document2:
      fig_caption: yes
      fig_height: 4
      fig_width: 6
      toc: yes
      reference_docx: "../templates/WDFW Report Template.docx" # Insert path for the DOCX file
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
bibliography:
  # - AUC.bib
  - references.bib
csl: "../templates/american-fisheries-society.csl" # Insert path for the bib-style
# abstract: |
---

```{r setup, echo = FALSE, message=F, warning=F}
library(knitr)
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/",
  dpi = 300
)
```

```{r packages}
# load these packages
library(tidyverse)
library(here)
library(magrittr)
library(janitor)
library(lubridate)
library(readxl)
library(splines)
library(mgcv)
library(ggfortify)
library(tidymv)
library(english)
library(ggpubr)
library(scales)
library(corrr)
library(colorspace)
library(kableExtra)

# set the default options for plots
theme_set(theme_bw(base_size = 14))

# knitr options
options(knitr.kable.NA = '-')

# when knitting to Word, use this
# what kind of document is being created?
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')

if(!is.null(doc.type)) {
  if(doc.type == 'docx') {
    options(knitr.table.format = "pandoc")
  }}

```

```{r load-data}
load(here("analysis/data/derived_data",
          "ops_data.rda"))

load(here("analysis/data/derived_data",
          "spp_comp_data.rda"))

load(here("analysis/data/derived_data",
          "spp_comp_pred.rda"))

# filter out 2018 from some data
sonar_pred_spp <-
  sonar_pred_spp |> 
  filter(year != 2018)

sonar_sthd <-
  sonar_sthd |> 
  filter(year != 2018)


load(here("analysis/data/derived_data",
          "time_series.rda"))
# preserve full time-series of observations, before it's overwritten by loading GAM results (which filter out 2018)
ts_obs_all = ts_half_hr

time_step = c("30 min",
              "1 hour")[1]
load(here("analysis/data/derived_data",
          paste0("gam_",
                 str_replace(time_step, " ", "_"),
                 ".rda")))
load(here("analysis/data/derived_data",
          paste0("gam_preds_",
                 str_replace(time_step, " ", "_"),
                 ".rda")))

load(here("analysis/data/derived_data",
          "obs_compare.rda"))

load(here("analysis/data/derived_data",
          "redd_comp.rda"))

```

```{r phos-calc}
phos_calc <-
  spp_comp |> 
  filter((is.na(rmu) | rmu < 6),
         (month(date) <= 6 |
            month(date) == 6 & mday(date) <= 15),
         (is.na(site) | str_detect(site, "Gray Wolf", negate = TRUE)),
         species == "Steelhead") |>
  filter(str_detect(comments, fixed("kelt", ignore_case = T), negate = T) |
           is.na(comments)) |>
  count(species,
        year, 
        mark_status) |> 
  pivot_wider(names_from = mark_status,
              values_from = n) |> 
  mutate(phos = AD / (AD + UM))

```


\newpage

# Executive Summary

This report contains methods and results of SONAR-based escapement estimates for naturally spawning winter steelhead on the Dungeness River from 2019-2023. The Washington Department of Fish and Wildlife (WDFW) deployed a multibeam SONAR unit in the lower Dungeness River during the majority of the steelhead return from either early February or early March through the end of June or July, 2018-2023. Although the SONAR was operated in 2018, we were not able to produce a SONAR-based escapement estimate for 2018 due to frequent milling behavior at the site, and limited data review. We initiated a sub-sampling protocol in 2019 to enable us to review the entire season of imagery, and this was continued in subsequent years. 

To exclude similarly sized fish that were not steelhead from our SONAR counts, WDFW conducted weekly species composition sampling in 2021, 2022 and 2023 throughout the periods of SONAR operation. The majority of fish encountered were steelhead and bull trout and these species overlapped in length. To exclude potential bull trout from the SONAR fish counts we fit a binomial generalized additive model (GAM) with a logit link, using splines of fork length and Julian day to predict the probability of a fish being a steelhead. The probability of being a steelhead was greatest during March and April, and least in February and June when fewer steelhead were present. 

To fill in the missing data from periods when the SONAR was not operating or the data had not been reviewed, we fit the fish count data with a negative binomial GAM with a log link function using hour of day, discharge, and Julian day-of-year as covariates. For both upstream and downstream moving fish, the model indicates that a greater number of steelhead will move during the night, especially in the late evening, compared to the daytime, and more will move when discharge flows are near 600 cfs. There is also a clear effect of day-of-year, with upstream numbers peaking near the beginning of April, while downstream numbers peak near the beginning of May, with some year-to-year variability in the run-timing curve. 

To generate an annual estimate of natural spawning escapement, we subtracted the total estimate of downstream moving fish from the total estimate of upstream moving fish from February 1 - May 15th to prevent double counting milling fish. After May 15, we ignored downstream moving fish and only estimated upstream moving fish, under the assumption that downstream moving fish are steelhead kelts that have spawned and therefore should not be subtracted from our escapement estimates. Total SONAR-based naturally spawning escapement estimates for steelhead ranged from `r round_half_up(min(comp_est$median))` (CI `r paste(round(as_vector(comp_est[which.min(comp_est$median), c(5,6)])), collapse = " - ") `) in `r comp_est$year[which.min(comp_est$median)]` to `r prettyNum(round_half_up(max(comp_est$median)), big.mark = ",")` (CI `r paste(prettyNum(round(as_vector(comp_est[which.max(comp_est$median), c(5,6)])), big.mark = ","), collapse = " - ") `) in `r comp_est$year[which.max(comp_est$median)]`. We did not estimate the proportion of hatchery-origin spawners (pHOS). The species composition sampling suggests a pHOS of `r paste(round(range(phos_calc$phos), 3) * 100, collapse = " - ")`% which is similar to hatchery-origin proportions from hook and line sampling in the Dungeness 2014- 2020 [@WDFW2024]. The SONAR-based estimates were consistently roughly twice the redd-based estimates.

We learned some important lessons over the first 6 years of SONAR operation on the Dungeness River. Site selection is important and may need to change if fish aren’t actively migrating past the site. For future seasons we recommend deploying the SONAR in January, to capture the start of the steelhead return. We also recommend considering re-designing the species composition sampling to attempt to exclude holding fish, and to investigate how species composition changes with hour of day, since returning steelhead appear to move primarily in the late evening. Finally, we recommend investigating methods to account for kelts that are less simplistic than the methods we used here, and investigating methods for estimating pHOS.

# Introduction

Dungeness River steelhead (*Oncorhynchus mykiss*) are part of the Puget Sound Steelhead Distinct Population Segment (DPS), which includes all naturally spawned steelhead below migration barriers in the rivers flowing into the Strait of Juan de Fuca from the Elwha (inclusive) eastward, Hood Canal, and Puget Sound [@Myers2015]. The Puget Sound steelhead DPS was listed as threatened under the Endangered Species Act (ESA) in May 2007, and subsequent species status reviews have upheld the threatened listing [@Ford2011; @NWFSC2015]. The Dungeness steelhead population is considered a mixed winter/summer run population. Historic accounts from the 1940s describe summer-run steelhead in the Dungeness River in July and August, but it is unclear whether a summer-run population still exists alongside or distinct from the winter population [@Myers2015]. Steelhead in the Dungeness spawn in the mainstem Dungeness up to a waterfall above Gold Creek (RKM 30), in the Gray Wolf River up to RKM 15.5, and in Canyon Creek up to RKM 2.7; there is also limited spawning in other small tributaries (e.g., Hurd Creek, Hatchery Creek).

In addition to the natural winter steelhead population, the Washington Department of Fish and Wildlife (WDFW) has released hatchery-propagated early winter steelhead (EWS) into the Dungeness River for decades to provide fishing opportunities for sport and tribal anglers. EWS have been selected for early maturation and early return and spawn timing; Dungeness EWS return to the Dungeness Hatchery (RKM 16.9) between late December and the end of January. All eggs are taken by January 31st to maintain temporal separation with the later timed natural winter steelhead population. EWS-directed fisheries occur in some years from the mouth to the Forks of the mainstem Dungeness and the Gray Wolf Rivers at RKM 25.4 between November 30 and January 31. 

The Dungeness River is snowmelt dominated and glacially influenced, with headwaters in the Olympic Mountains [@Myers2015]. Glacial sediments and springtime snowmelt can lead to high, turbid water and unsafe survey conditions, presenting a challenge to steelhead redds surveys in the basin. In most years it is not possible to survey for steelhead through the entirety of the spawning season, and in some years poor survey conditions prevent an adequate number of surveys from being completed to produce an estimate of escapement based on redd counts. Current methods use a run-timing curve from 2015, a low water year in which redds surveys could be conducted through the entire spawning period, to expand the current year’s redd counts to generate an escapement estimate. However, this method does not account for the annual variation in flows and spawn timing, which limits accuracy of abundance estimates. Accurate estimates of steelhead escapement in the Dungeness are important to monitor the abundance and health of the population, to evaluate progress towards ESA recovery goals, and to manage potential future fisheries.

SONAR may provide an alternative method for steelhead enumeration and run timing in a dynamic, turbid snow-melt system like the Dungeness watershed. SONAR can be operated in a range of flow conditions and is not limited by turbidity. Since 2018 WDFW has operated a stationary multi-beam SONAR unit in the lower Dungeness River to enumerate and gather run-timing information on Dungeness steelhead. This is our first report on the SONAR project, covering the 2018-2023 seasons.

# Methods

## SONAR operation

We deployed the ARIS 1800 Explorer, manufactured by Sound Metrics, of Bellevue, Washington in the lower Dungeness River during the majority of the steelhead run from 2018 through 2023 (Figure \@ref(fig:wtsd-map)). The ARIS 1800 uses 96 beams at 1.1/1.8 megahertz (Mhz) to project a 28-degree acoustic wedge. The SONAR unit was adjusted to have a pitch of 3.5 degrees to -8 degrees to ensonify the entire water column and channel. The unit was checked daily and adjusted as necessary to maintain full ensonification of the channel. Imagery was continuously recorded 24 hours a day, and saved in 30-minute files, so that 48 individual files were recorded for each full day of operation.

```{r wtsd-map, out.width = "90%", fig.align="center", fig.cap = "Location of SONAR in Dungeness River basin. Steelhead distribution shown in black."}
include_graphics(here("analysis/images/sonar_mapRKM.jpg"))
```

In 2018 the SONAR unit was deployed at approximately at river kilometer (RKM) 0.3, below the majority of steelhead spawning habitat, and ensonified an approximately 20 meter (m) wide run in the river (Figure \@ref(fig:site-map)). The SONAR unit was mounted to a pole mount and attached to a reinforced ladder, secured to the river bottom by rebar (Figure \@ref(fig:setup-2018)). 

Fish frequently milled or held in front of this SONAR site, which made counting fish passage difficult. As a result, in 2019, the SONAR site was moved upstream to approximately RKM 0.5, to a site with higher velocity, past which fish actively migrated (Figure \@ref(fig:setup-2019)). This site was easily accessible from the field trailer site, which enabled the unit to be directly connected and powered by trailer power, and any adjustments to the SONAR settings to be accomplished in the dry, safe comfort of the trailer. 

```{r site-map, out.width = "70%", fig.align="center", fig.cap = "Location of the SONAR site in the lower Dungeness River in 2018 (white) and 2019-2023 (striped)."}
include_graphics(here("analysis/images/site_map.png"))
```

```{r setup-2018, out.width = "70%", fig.align="center", fig.cap = "SONAR unit deployment via a pole mount and ladder system in the Dungeness River in 2018."}
include_graphics(here("analysis/images/setup_2018.jpg"))
```

Midway through the 2019 season the SONAR unit was mounted on a semi-permanent platform along the hardened west bank, in a spot that is protected and retains adequate depth so that the SONAR unit did not need to be shifted laterally to accommodate changing water levels (Figure \@ref(fig:setup-2019)). 

In all years, a picket weir was constructed approximately 1 meter upstream of the SONAR unit from the bank, extending out to approximately 1 meter past the SONAR, to deflect debris (Figure \@ref(fig:setup-2019)). A second picket weir was constructed approximately 1 meter downstream of the SONAR unit to direct migrating fish out in front of the unit. 

```{r setup-2019, out.width = "70%", fig.align="center", fig.cap = "SONAR unit deployment via a pole mount and platform in the Dungeness River in 2020. Picket weir is the upstream picket weir."}
include_graphics(here("analysis/images/setup_2019.jpg"))
```

The SONAR was operated from early February or early March through late June or mid- to late July each year (Table \@ref(tab:op-dates), Figure \@ref(fig:op-fig)). Other than a 22-day suspension in 2020 due to COVID-19 protocols, there were few outages and gaps in data collection (Table \@ref(tab:op-dates), Figure \@ref(fig:op-fig)). SONAR imagery was reviewed for steelhead passage from the first day of operation through at least June 20th in each year.

```{r op-dates}
ops_df |> 
  filter(time_scale == "Day") |> 
  unnest(ops) |>
  filter(op_perc > 0) |> 
  group_by(year) |> 
  summarize(across(date,
                   list(first = ~ min(.),
                        last = ~ max(.)),
                   .names = "{.fn}_{.col}")) |> 
  mutate(across(
    ends_with("date"),
    ~ format(., "%b %d")
  )) |> 
  clean_names("title") |> 
  kable(booktabs = T,
        linesep = "",
        caption = "SONAR operational dates on the Dungeness River, 2018 - 2023.") |> 
  kable_styling(latex_options = c("hold_position"))


```

```{r op-fig, fig.height = 3.8, fig.width = 7, fig.cap = "Plot of when SONAR was operational (purple) and not (yellow), from February 1 through July 31 each year."}
half_hr_periods %>%
  mutate(hr = as.numeric(hour) / (60*60)) %>%
  mutate(date = as.Date(paste(month(date), mday(date)), format = "%m %d")) %>%
  # filter(month(date) <= 6) %>%
  ggplot(aes(x = date,
             y = hr,
             color = operational,
             fill = operational)) +
  geom_tile() +
  scale_fill_viridis_d(direction = -1,
                       name = "Sonar\nOperational") +
  scale_color_viridis_d(direction = -1,
                        name = "Sonar\nOperational") +
  facet_wrap(~ year,
             scales = "fixed") +
  scale_x_date(breaks = scales::breaks_pretty(7)) +
  labs(x = "Date",
       y = "Hour") +
  theme(legend.position = "right",
        axis.text.x = element_text(angle = 90,
                                   hjust = 1))
```

```{r review-fig, fig.height = 3.8, fig.width = 7, fig.cap = "Plot of when SONAR was reviewed (purple) and not (yellow), from February 1 through July 31 each year."}
half_hr_periods %>%
  mutate(hr = as.numeric(hour) / (60*60),
         half_hr = as.numeric(time) / (60*60)) %>%
  mutate(date = as.Date(paste(month(date), mday(date)), format = "%m %d")) %>%
  # filter(month(date) <= 6) %>%
  ggplot(aes(x = date,
             y = half_hr,
             color = reviewed,
             fill = reviewed)) +
  geom_tile() +
  scale_fill_viridis_d(direction = -1,
                       name = "Sonar\nReviewed") +
  scale_color_viridis_d(direction = -1,
                        name = "Sonar\nReviewed") +
  facet_wrap(~ year,
             scales = "fixed") +
  scale_x_date(breaks = scales::breaks_pretty(7)) +
  labs(x = "Date",
       y = "Hour") +
  theme(legend.position = "right",
        axis.text.x = element_text(angle = 90,
                                   hjust = 1))
```

\FloatBarrier

## Data Processing

In 2018 we reviewed both 30-minute files in each hour, for a total of 48 files per 24-hour period. Data review for 2018 was time-consuming and onerous due to the number of fish milling in front of the SONAR, and we were only able to review 29% of the recorded SONAR imagery over the season (Table \@ref(tab:pct-ops)). Because of the immense quantity of SONAR files, and the amount of time it took to process and review each 30-minute file, in 2019 we initiated a subsampling design to enable the project team to review portions of nearly every day in the entire period of steelhead passage. In 2019 - 2023 the first 30 minutes of each hour were processed and reviewed for fish migration, while a subset of days was fully reviewed (60 minutes of each hour) as time allowed. Another subset of days was double, or triple, reviewed to compare fish counts and lengths among each year’s two or three data reviewers. Table \@ref(tab:pct-ops) shows what percentage of the total hours were reviewed each year (from February 1 - June 15), and what percentage of that period the SONAR was operating and collecting data.

```{r op-rev, eval = F}
half_hr_periods |> 
  mutate(month(date) < 6 |
           (month(date) == 6 & day(date) <= 15)) |> 
  mutate(across(year,
                as_factor)) |> 
  group_by(year) |> 
  summarize(n_half_hours = n(), 
            n_op = sum(operational), 
            n_rev = sum(reviewed),
            .groups = "drop") |> 
  mutate(across(starts_with("n"), 
                ~ . / 2),
         across(c(n_op,
                  n_rev),
                ~ . / n_half_hours * 100)) |> 
  rename(n_hrs = n_half_hours) |> 
  kable(col.names = c("Year",
                      "Hours",
                      "Operational (%)",
                      "Reviewed (%)"),
        booktabs = T,
        linesep = "",
        digits = c(0, 0,
                   1, 1),
        format.args = list(big.mark = ","),
        caption = "Number of hours during winter steelhead migration period (February 1 - June 15) and what percentage of those hours the SONAR was operational and what percentage of those hours have been reviewed.") |> 
  kable_styling(latex_options = c("HOLD_position"))
```

```{r pct-ops}
half_hr_periods |>
  filter(month(date) < 6 |
           (month(date) == 6 & day(date) <= 15)) |>
  mutate(across(year,
                as.factor)) |> 
  group_by(year) |> 
  summarize(first_day = min(date),
            last_day = max(date),
            n_periods = n_distinct(date_time),
            n_operational = sum(operational),
            n_reviewed = sum(reviewed),
            pct_operational = n_operational / n_periods,
            pct_reviewed = n_reviewed / n_periods,
            .groups = "drop") |> 
  select(-starts_with("n_")) |> 
  mutate(across(ends_with('day'),
                ~ format(., "%b %d"))) |> 
  adorn_pct_formatting(digits = 1,
                       rounding = "half up",
                       affix_sign = TRUE,
                       starts_with("pct")) |> 
  clean_names("title") |>
  rlang::set_names(function(x) {
    str_replace(x, "^N ", "n ")
  }) |> 
  kable(booktabs = T,
        linesep = "",
        format.args = list(big.mark = ","),
        caption = "The percentage of time between February and mid-June that the SONAR was operational, and how much of the total time was reviewed, 2018 - 2023.") |> 
  kable_styling(latex_options = c("hold_position"))
```


Each reviewed imagery file was processed using Sound Metric’s proprietary software ARISFish (v2.6.3 – v2.8.0). First, raw image files were background subtracted, which removed static objects from the image so that only objects in motion are shown. Then, an echogram was created, which transformed the image into a graph of distance (y-axis) and time (x-axis), so that objects in motion appeared as white “tracks.” The echogram enabled the data reviewer to quickly navigate to parts of the image file that contained objects that could be migrating fish. These tracks were then manually viewed alongside the raw image file to determine if the object was a fish to be further investigated. 

Fish greater or equal to 45 centimeters (cm) were measured, marked, and counted using the ARISFish software. Forty-five cm was determined to be the minimum length of a potential steelhead, based on captures of steelhead during sampling in the Dungeness River 2014, 2015, and 2017 by the Jamestown S’Klallam Tribe (JSK) (unpublished data, C. Burns). Only fish that completely moved through the SONAR beams were counted; fish that nosed in and out or did not completely move from one side of the beams to the other were not counted.

For each fish counted the following data were recorded:

* Date
* Hour of the 30-minute image file (e.g., 14:00, 14:30)
* Time 
* Frame
* Direction of travel (upstream or downstream)
* Range (distance from the SONAR)
* Length of the fish in cm
* Data reviewer confidence (1 = extremely confident that the object counted is a fish $\geq$ 45 cm, 2 = somewhat confident that the object is a fish $\geq$ 45 cm, 3 = object of interest)

If no fish were observed in the 30-minute image file, a line of data with “NO FISH” was recorded to indicate that the file was reviewed for fish, but no fish $\geq$ 45 cm were present. Counted fish were automatically saved within the image file for later error checking; data were also recorded within an Excel spreadsheet for data summarization and analysis. 

## Data Reviewer Comparison

```{r}
# correlation between counts
obs_day_cor_tmp <-
  mult_obs_df |>
  nest(obs_df = -c(direction)) |>
  arrange(desc(direction)) |>
  mutate(n_obs = map_dbl(obs_df,
                         .f = function(x) {
                           n_distinct(x$observer)
                         }),
         n_AS = map_dbl(obs_df,
                        .f = function(x) {
                          sum(x$observer == "AS")
                        }),
         n_pairs = map(obs_df,
                       .f = function(x) {
                         x |>
                           select(year,
                                  date, 
                                  observer) |> 
                           distinct() |> 
                           mutate(used = 1) |> 
                           pivot_wider(names_from = observer,
                                       values_from = used,
                                       values_fill = 0) |>  
                           select(-c(year, date)) %>%
                           nest(n_dates = everything()) |> 
                           mutate(cross_p = map(n_dates,
                                                .f = function(y) {
                                                  y |> 
                                                    as.matrix() |> 
                                                    crossprod() %>%
                                                    as_tibble(rownames = "obs_1") |> 
                                                    pivot_longer(-obs_1,
                                                                 names_to = "obs_2",
                                                                 values_to = "n_days") |> 
                                                    filter(n_days > 0)
                                                })) |> 
                           unnest(cross_p) |> 
                           select(-n_dates) |> 
                           filter(obs_1 != obs_2)
                       }),
         obs_corr = map(obs_df,
                        .f = function(x) {
                          x |>
                            group_by(date,
                                     observer) |>
                            summarize(n_fish = n(),
                                      .groups = "drop") |>
                            pivot_wider(names_from = observer,
                                        values_from = n_fish) |>
                            select(-date) |>
                            corrr::correlate(quiet = T) |>
                            corrr::stretch(na.rm = T,
                                           remove.dups = T) |>
                            rename(obs_1 = x,
                                   obs_2 = y)
                        }))

obs_day_cor <-
  obs_day_cor_tmp |>
  unnest(obs_corr) |>
  left_join(obs_day_cor_tmp |>
              unnest(n_pairs),
            by = join_by(direction, obs_df, n_obs, n_AS, obs_1, obs_2)) |> 
  select(direction, 
         obs_1,
         obs_2,
         n_days,
         r) |> 
  left_join(mult_obs_df |> 
              group_by(direction,
                       date) |> 
              count(observer) |> 
              pivot_wider(names_from = observer,
                          values_from = n) |> 
              pivot_longer(cols = -c(date, 
                                     direction, 
                                     AS),
                           names_to = "observer",
                           values_to = "cnt") |> 
              filter(!is.na(cnt)) |> 
              group_by(direction,
                       obs_2 = observer) |> 
              summarize(obs_1_fish = sum(AS, na.rm = T),
                        obs_2_fish = sum(cnt, na.rm = T),
                        .groups = "drop") |> 
              add_column(obs_1 = "AS",
                         .before = "obs_2") |> 
              bind_rows(mult_obs_df |> 
                          group_by(direction,
                                   date) |> 
                          count(observer) |> 
                          pivot_wider(names_from = observer,
                                      values_from = n) |> 
                          pivot_longer(cols = -c(date, 
                                                 direction, 
                                                 BC),
                                       names_to = "observer",
                                       values_to = "cnt") |> 
                          filter(!is.na(cnt)) |> 
                          group_by(direction,
                                   obs_2 = observer) |> 
                          summarize(obs_1_fish = sum(BC, na.rm = T),
                                    obs_2_fish = sum(cnt, na.rm = T),
                                    .groups = "drop") |> 
                          add_column(obs_1 = "BC",
                                     .before = "obs_2")) |> 
              bind_rows(mult_obs_df |> 
                          group_by(direction,
                                   date) |> 
                          count(observer) |> 
                          pivot_wider(names_from = observer,
                                      values_from = n) |> 
                          pivot_longer(cols = -c(date, 
                                                 direction, 
                                                 CS),
                                       names_to = "observer",
                                       values_to = "cnt") |> 
                          filter(!is.na(cnt)) |> 
                          group_by(direction,
                                   obs_2 = observer) |> 
                          summarize(obs_1_fish = sum(CS, na.rm = T),
                                    obs_2_fish = sum(cnt, na.rm = T),
                                    .groups = "drop") |> 
                          add_column(obs_1 = "CS",
                                     .before = "obs_2")) |> 
              bind_rows(mult_obs_df |> 
                          group_by(direction,
                                   date) |> 
                          count(observer) |> 
                          pivot_wider(names_from = observer,
                                      values_from = n) |> 
                          pivot_longer(cols = -c(date, 
                                                 direction, 
                                                 AB),
                                       names_to = "observer",
                                       values_to = "cnt") |> 
                          filter(!is.na(cnt)) |> 
                          group_by(direction,
                                   obs_2 = observer) |> 
                          summarize(obs_1_fish = sum(AB, na.rm = T),
                                    obs_2_fish = sum(cnt, na.rm = T),
                                    .groups = "drop") |> 
                          add_column(obs_1 = "AB",
                                     .before = "obs_2")),
            by = join_by(direction, obs_1, obs_2)) |> 
  relocate(r,
           .after = obs_2_fish)


```

```{r}
day_cnts <- mult_obs_fish |>
  group_by(year, date,
           direction,
           observer) |> 
  summarize(n_cnts = n_distinct(fish_num),
            .groups = "drop") |> 
  pivot_wider(names_from = observer,
              values_from = n_cnts,
              names_sort = T)

comp_list = NULL
grp = 1
for(i in unique(mult_obs_fish$observer)) {
  for(j in unique(mult_obs_fish$observer)) {
    if(i == j) next
    cnt_comp <- day_cnts |> 
      select(year:direction,
             all_of(c(i,j)))
    names(cnt_comp)[c(4, 5)] = c("obs_1", "obs_2")
    cnt_comp <- cnt_comp |> 
      filter(!is.na(obs_1),
             !is.na(obs_2))
    
    cnt_totals <- cnt_comp |> 
      group_by(year,
               direction) |> 
      summarize(across(c(obs_1,
                         obs_2),
                       sum),
                .groups = "drop")
    
    names(cnt_totals)[c(3, 4)] = c(i, j)
    
    comp_list[[grp]] = cnt_totals |> 
      pivot_longer(-c(year, direction),
                   names_to = "observer",
                   values_to = "cnts")
    
    grp = grp + 1
    
  }
}  

obs_cnt_comp <- map_df(comp_list,
                       .f = identity,
                       .id = "grp") |> 
  arrange(desc(direction),
          year) |> 
  pivot_wider(names_from = observer,
              values_from = cnts) |> 
  select(any_of(names(day_cnts))) |> 
  distinct()
```

In several years (`r paste(range(mult_obs_df$year), collapse = " - ")`), a subset of SONAR footage was reviewed by all (two or three) of that years' observers (Table \@ref(tab:obs-rev-tab)). Within that subset of data, we summed the counts of each observer by date and direction before calculating the correlations between counts of different observers using the Pearson correlation coefficient. One observer (initial AS) was an observer every year, while other observers worked for one or two years only. We combined the daily counts across years when computing the correlation between observers. We also computed separate correlations for upstream and downstream counts.

To compare length measurements, we attempted to group individual observer detections of the same fish. We did this by first grouping fish detected in the same hour period moving in the same direction. If there was more than one fish detected in that group, we assumed that the relative lengths assigned by each observer corresponded to the same fish (i.e. the smallest observed fish by observer A was also the smallest observed fish by observer B). We then calculated the mean, standard deviation and coefficient of variation (CV) of the length measurements for each fish. Because observer AS was the most experienced, and measured nearly every fish, we also compared other observer length measurements against those by AS and treated the measurements by AS as the benchmark for these comparisons. We summarized those differences with statistics such as mean bias, mean absolute error (MAE), root mean squared error (RMSE) and mean absolute percent error (MAPE). 

```{r as-length}
as_length_comp <- 
  mult_obs_fish |>
  group_by(year,
           date_time,
           direction,
           fish_num,
           observer) |>
  summarize(
    across(
      length,
      mean),
    .groups = "drop"
  ) |>
  pivot_wider(names_from = observer,
              values_from = length) |>
  pivot_longer(-c(year:AS),
               names_to = "observer",
               values_to = "length") |>
  filter(!is.na(AS),
         !is.na(length)) |>
  mutate(bias = length - AS,
         rel_bias = bias / AS) |> 
  mutate(across(direction,
                str_to_title))
```


```{r obs-rev-tab}
mult_obs_fish |> 
  group_by(year) |> 
  summarize(n_days = n_distinct(date),
            n_hrs = n_distinct(date_time),
            n_fish = n_distinct(fish_num)) |> 
  kable(col.names = c("Year",
                      "n Days",
                      "n Hours",
                      "n Fish"),
        booktabs = T,
        linesep = "",
        digits = 0,
        caption = "Number of distinct days, hours and individual fish that were double or triple reviewed each year.") |>
  kable_styling(latex_options = c("hold_position"))
```

\FloatBarrier

## Species Composition Sampling

Species composition sampling was conducted weekly, as river conditions allowed, during the period of SONAR operations in 2021, 2022 and 2023. A fine monofilament gill net 5.5 meters wide by 2.4 meters deep with a 5-cm mesh (10-cm stretch) was drifted through all sampleable habitat in the lower river from RKM 5.3 to RKM 0.8 (2021) or RKM 1.3 (2022 - 2023). In habitat where it wasn't possible to use a net (e.g., too much wood), hook and line sampling occurred. Encountered fish were removed immediately from the net, sedated in a solution of tricaine methanesulfonate (MS-222), and sampled for species, mark status, length, sex, scales, and DNA. Hatchery-origin steelhead were identified by adipose fin clip. Captured steelhead were assessed for kelt status. 

No regular species composition sampling was conducted in 2018, 2019, or 2020. In 2019, three sampling efforts targeting bull trout (*Salvelinus confluentus*) were conducted once per week in June at sites throughout the Dungeness and Gray Wolf rivers.

## Determining Species

Bull trout moved past the SONAR unit as well as steelhead. We needed to parse which fish identified by the SONAR were steelhead, and exclude any bull trout. We modeled the probability of a fish being a steelhead using fork length and the Julian day of capture from the 2021-2023 species composition data, including both natural-origin and hatchery-origin steelhead. Since our primary objective was differentiating steelhead from other fish, we grouped resident rainbow and cutthroat trout (*Oncorhynchus clarkii*) with bull trout, and then fit a binomial generalized additive model (GAM) with a logit link, using splines of fork length and Julian day, to predict the probability of a fish being a steelhead.

After fitting this GAM, we predicted the probability of being a steelhead for all fish observed on the SONAR. Any fish with a probability of 50% or greater we assigned as a steelhead. 

## Abundance Estimation

Although data was collected for the 2018 run year, the data quality was insufficient to estimate a steelhead abundance for that year. Because we observed frequent milling behavior at the SONAR site, upstream and downstream counts were much higher than subsequent years, and only 29% of the season was reviewed (Table \@ref(tab:pct-ops)), so we treated 2018 as a pilot year and did not make an escapement estimate.

For 2019 - 2023, SONAR fish targets that had a greater than or equal to 50% probability of being a steelhead, moved completely through the SONAR beams (direction of travel was upstream or downstream), and had a data reviewer confidence of 1 were included in the final steelhead counts and abundance estimate. Based in part on the species composition data, we determined that the steelhead run on the Dungeness is over by mid-June, so we restricted the steelhead season to SONAR observations or predictions between February 1 and June 15. 

```{r year-est}
time_step = c("30 min",
              "1 hour")[1]

day_draws <- read_rds(here("analysis/data/derived_data",
                           paste0("mcmc_draws_day_",
                                  str_replace(time_step, " ", "_"),
                                  ".rds"))) |> 
  pivot_wider(names_from = direction,
              values_from = value) |> 
  filter(draw != 359) |> 
  mutate(net = up - down) |> 
  pivot_longer(cols = c(down,
                        up, 
                        net),
               names_to = "direction",
               values_to = "value") |> 
  mutate(across(direction,
                ~ factor(.,
                         levels = c("up", "down", "net")))) |> 
  mutate(year = year(date)) |> 
  relocate(year, .before = 0)

down_date <- "May 15"

yr_draws_net <- day_draws |> 
  filter(direction == "net",
         date < ymd(paste(year, down_date))) |> 
  group_by(year,
           draw,
           direction) |> 
  summarize(across(value,
                   sum),
            .groups = "drop")

yr_draws_up <- day_draws |> 
  filter(direction == "up",
         date >= ymd(paste(year, down_date))) |> 
  group_by(year,
           draw,
           direction) |> 
  summarize(across(value,
                   sum),
            .groups = "drop")

yr_draws_kelts <- day_draws |> 
  filter(direction == "down",
         date >= ymd(paste(year, down_date))) |> 
  group_by(year,
           draw,
           direction) |> 
  summarize(across(value,
                   sum),
            .groups = "drop") |> 
  rename(kelts = value)

yr_draws <- yr_draws_net |> 
  bind_rows(yr_draws_up) |> 
  pivot_wider(names_from = direction,
              values_from = value) |> 
  mutate(total = net + up)

# summary statistics
yr_est <- yr_draws |>
  pivot_longer(c(net, up, total),
               names_to = "group",
               values_to = "value") |> 
  group_by(year,
           group) |>
  summarize(
    across(
      value,
      list(mean = ~ mean(.),
           median = ~ median(.),
           se = ~ sd(.)),
      .names = "{.fn}"),
    .groups = "drop") |>
  left_join(yr_draws |>
              pivot_longer(c(net, up, total),
                           names_to = "group",
                           values_to = "value") |> 
              group_by(year,
                       group) |>
              reframe(across(value,
                             ~ quantile(., c(0.025, 0.975)))) %>%
              add_column(quantile = rep(c("2.5%", "97.5%"), nrow(.) / 2)) |>
              pivot_wider(names_from = quantile,
                          values_from = value),
            by = join_by(year, group)) |> 
  mutate(across(group,
                ~ case_match(.,
                             "net" ~ "early",
                             "up" ~ "late",
                             .default = .)),
         across(group,
                ~ factor(.,
                         levels = c("early",
                                    "late",
                                    "total")))) |> 
  arrange(year, group)
```

```{r year-est-old, eval = F}
time_step = c("30 min",
              "1 hour")[1]
yr_draws <- read_rds(here("analysis/data/derived_data",
                          paste0("mcmc_draws_year_",
                                 str_replace(time_step, " ", "_"),
                                 ".rds")))
yr_draws_net <- yr_draws |> 
  pivot_wider(names_from = direction,
              values_from = value) |> 
  mutate(net = up - down) |> 
  pivot_longer(cols = c(down,
                        up, 
                        net),
               names_to = "direction",
               values_to = "value") |> 
  mutate(across(direction,
                ~ factor(.,
                         levels = c("up", "down", "net"))))

yr_est <- yr_draws_net |>
  group_by(year,
           direction) |>
  summarize(
    across(
      value,
      list(mean = ~ mean(.),
           median = ~ median(.),
           se = ~ sd(.)),
      .names = "{.fn}"),
    .groups = "drop") |>
  left_join(yr_draws_net |>
              group_by(year,
                       direction) |>
              reframe(across(value,
                             ~ quantile(., c(0.025, 0.5, 0.975)))) %>%
              add_column(quantile = rep(c("2.5%", "50%", "97.5%"), nrow(.) / 3)) |>
              pivot_wider(names_from = quantile,
                          values_from = value),
            by = join_by(year))
```

To fill in the missing data from periods when the SONAR was not operating or the data had not been reviewed, this dataset was fit with a negative binomial generalized additive model (GAM) with a log link function using hour of day, discharge (from USGS gage 12048000 on the Dungeness River, summarized at the hour timescale) and Julian day-of-year as covariates. The GAM include a cubic spline for the hour of day, a thin-plate spline for discharge, and a factor spline for day of year, including an interaction between year and day of year. This GAM was then used to predict the upstream and downstream numbers of steelhead during all missing data periods, from February 1 through June 15 each year. This included all half hours when the SONAR was not operational for the entire 30 min, as well as all half hours that were not reviewed. 

```{r abund-form, eval = F}
print(formula(up_mod))
# print(up_mod$call)
```

```{r, eval = F}
up_mod$model |> 
  as_tibble() |> 
  select(-matches("offset")) |> 
  # filter(total_observed_hr > 3)
  filter(day_of_year > 90) |> 
  head(10) |> 
  print()
```

To combine the upstream and downstream estimates, we made one simplifying assumption related to kelting behavior similar to the process outlined in @Metheny2012 and @Metheny2014. Prior to `r down_date`, we subtracted the total estimate of downstream moving fish from the total estimate of upstream moving fish. This is to prevent fish that are milling (moving upstream, then downstream, then upstream again) from being double counted. After `r down_date`, we ignored downstream moving fish and only estimated upstream moving fish, under the assumption that downstream moving fish were steelhead kelts that had spawned and therefore should not be subtracted from our escapement estimates. Obviously, there may be kelts moving downstream prior to `r down_date`, and there may be milling fish after that date, but our assumption was that the number of downstream moving kelts prior to that date equals the number of downstream milling fish after that date. 

### Comparison with Redd-Based Estimates

The Jamestown S’Klallam Tribe has conducted redd surveys for steelhead on the Dungeness for many years. In most years, rising flows and increased turbidity close the river to surveyors before the end of steelhead spawning season. However, in 2015, conditions allowed for surveys to be completed through the end of the spawning season. For other years, the number of redds surveyed is expanded by the proportion of total redds observed in 2015 up to the date of the last survey in that year. These estimates of total redds are then expanded to spawners by multiplying by a fish / redd constant of 1.62. We compared the SONAR-based estimates of steelhead escapement to the redd-based estimates of steelhead spawners for 2019, 2021, 2022 and 2023. Due to COVID, no redd surveys were conducted in 2020, so no redd-based estimate was available for that year. 

\FloatBarrier

# Results

## Data Reviewer Comparison

After summing the counts across days when each pair of observers reviewed the same footage, Table \@ref(tab:obs-totals) shows the total counts by year and direction (upstream vs. downstream) for each observer. Generally, the upstream counts are very well aligned, and the downstream counts are close, although they show more observer-to-observer variability than upstream counts. 

```{r obs-totals}
obs_cnt_comp |> 
  arrange(desc(direction),
          year) |> 
  mutate(across(direction,
                str_to_title)) |> 
  rename(Direction = direction,
         Year = year) |> 
  kable(booktabs = T,
        linesep = "",
        caption = "Total counts of steelhead by direction and year for each observer pair during days when both observers were counting.") |> 
  kable_styling(latex_options = c("hold_position")) |> 
  row_spec(row = sum(obs_cnt_comp$direction == "upstream"),
           hline_after = T) |> 
  collapse_rows(c(1,2))

```

The correlation coefficient between each pair of observers, by direction, is shown in Table \@ref(tab:obs-corr). Except for observer GB, correlations for upstream moving fish were all greater than 0.95, while the correlation coefficients for downstream moving fish ranged from `r paste(round(range(obs_day_cor$r[obs_day_cor$direction == "downstream"]), 2), collapse = " to ")`. Several of the weakest correlations corresponded with lower numbers of observed fish. 

```{r obs-corr}
obs_day_cor |>
  arrange(desc(direction),
          desc(r)) |> 
  mutate(across(direction,
                ~ str_to_title(.))) |> 
  clean_names("title") |> 
  rename(r = R) |> 
  kable(digits = c(rep(0,6),
                   3),
        booktabs = T,
        linesep = "",
        caption = "Correlation (r) between daily counts of upstream and downstream moving fish for periods that were reviewed by pairs of observers. The total number of days when each pair reviewed SONAR data is shown, as well as the total number of fish observed by each observer.") |> 
  kable_styling(latex_options = c("hold_position")) |> 
  row_spec(row = sum(obs_day_cor$direction == "upstream"),
           hline_after = T) |> 
  collapse_rows(1)
```

For fish observed by multiple observers, the CVs of those multiple length measurements are displayed in Figure \@ref(fig:cv-lgth-hist). The mean CV of length measurements for upstream moving fish was 0.09, while it was 0.10 for downstream moving fish. 86% of the upstream CVs were smaller than 0.15 (considered a reference point for precise measurements), while 78% of the downstream CVs met this criterion. 

```{r cv-lgth-hist, fig.cap = "Coefficient of variation (CV) of length measurements for individual fish across multiple observers, colored by year and faceted by direction of movement. Dashed lines indicate the mean CV for that group, while the solid black line is a reference of 0.15."}
mult_obs_fish |>
  filter(n_cnts > 1) |>
  group_by(year,
           fish_num,
           direction,
           n_cnts) |>
  summarize(mean_length = mean(length),
            sd_length = sd(length),
            cv_length = sd(length) / mean(length),
            .groups = "drop") |>
  mutate(across(year,
                as.factor),
         across(direction,
                str_to_title)) |>
  group_by(year,
           direction) |>
  mutate(cv_mean = mean(cv_length)) |>
  ungroup() |>
  ggplot(aes(x = cv_length,
             color = year,
             fill = year)) +
  scale_colour_discrete_qualitative(name = "Year") +
  scale_fill_discrete_qualitative(name = "Year") +
  geom_histogram(position = "dodge",
                 binwidth = 0.05) +
  geom_vline(xintercept = 0.15,
             linetype = 1) +
  geom_vline(aes(color = year,
                 xintercept = cv_mean),
             linetype = 2) +
  facet_wrap(~ direction) +
  labs(x = "CV of Length Measurements")

```

Histograms of length measurement bias, relative to observer AS, are shown in Figure \@ref(fig:lgth-comp-fig). Summary statistics of the same comparison are depicted in Table \@ref(tab:lgth-comp-tab). All observers had larger variability in their measurements of downstream moving fish compared to observer AS, as seen in RMSE, MAE and MAPE values. Three observers (AB, BT and GB) had a positive mean bias relative to observer AS for upstream fish and AB and BT also had a positive mean bias for downstream fish, meaning they often measured the same fish as being slightly larger than AS. The other observers had negative mean bias, meaning they measured the same fish as being smaller compared to observer AS. This was more pronounced for downstream moving fish, up to an mean difference of nearly -12.4 cm per fish for observer BC (although that observer only measured four downstream fish). 

The mean absolute percent error (MAPE) ranged from 6.7 - 12.3% for upstream moving fish and from 8.9 - 18.2% for downstream moving fish. To put that on the scale of fish lengths (centimeters), the root mean square error (RMSE) ranged from 6.7 - 9.9 cm for upstream moving fish and 6.8 - 17 cm for downstream moving fish.

```{r lgth-comp-fig, fig.cap = "Histograms and density plots showing the bias of length measurements, relative to observer AS, colored by observer and faceted by direction and year."}
as_length_comp |> 
  ggplot(aes(x = bias,
             color = observer,
             fill = observer)) +
  # geom_histogram(position = "dodge") +
  geom_histogram(aes(y = after_stat(density)),
                 binwidth = 5,
                 position = "dodge") +
  geom_density(alpha = 0.2) +
  geom_vline(xintercept = 0) +
  scale_colour_discrete_qualitative(name = "Observer") +
  scale_fill_discrete_qualitative(name = "Observer") +
  facet_grid(year ~ direction) +
  labs(x = "Length Bias (cm)\nRelative to Observer AS",
       y = "Density")
```


```{r lgth-comp-tab}
as_length_comp |>
  group_by(direction,
           # year,
           observer) |>
  summarize(n_fish = n_distinct(fish_num),
            mean_bias = mean(bias),
            RMSE = sqrt(mean(bias^2)),
            # RMSLE = sqrt(mean((log(length) - log(AS))^2)),
            MAE = mean(abs(bias)),
            MedAE = median(abs(bias)),
            MAPE = mean(abs(rel_bias)) * 100,
            MedAPE = median(abs(rel_bias)) * 100,
            .groups = "drop") |>
  arrange(desc(direction),
          desc(n_fish)) |> 
  clean_names("title") |> 
  rename(RMSE = Rmse,
         # RMSLE = Rmsle,
         MAE = Mae,
         MAPE = Mape) |> 
  # rename(Direction = direction,
  #        Observer = observer,
  #        `n Fish` = n_fish,
  #        `Mean Bias` = mean_bias) |> 
  select(-starts_with("Med")) |> 
  kable(digits = 1,
        booktabs = T,
        linesep = "",
        caption = "Summary statistics comparing length measurements of different observers with those made by observer AS.") |> 
  kable_styling(latex_options = c("hold_position")) |> 
  row_spec(row = 7,
           hline_after = T)

```

\FloatBarrier

## Species Composition

`r n_distinct(spp_fl$date) |> as.english() |> str_to_sentence()` species composition sampling events were conducted between early February and late June across 2021, 2022 and 2023. Steelhead and bull trout were the primary species encountered during sampling. The majority of captured steelhead were natural-origin. Two hatchery-origin steelhead were captured in early April 2021, three hatchery-origin steelhead were captured in mid-March of 2022, and four hatchery-origin steelhead were captured in 2023: one in early February, one in early March, and two in late April (Table \@ref(tab:spp-cnts-date)). All hatchery-origin steelhead were encountered after the last observed steelhead entered the Dungeness Hatchery each year (WDFW, FishBooks Hatchery Database), and are included here in our estimates of escapement. Steelhead kelts were encountered starting in June 2021, May 2022, and mid-April 2023 (Table \@ref(tab:spp-cnts-date)). From the species composition netting, there are `r nrow(spp_fl)` fish to use in this model. The lengths of these fish can be seen in Figure \@ref(fig:fl-hist). 

```{r spp-cnts-yr, eval = F}
spp_fl |>
# spp_comp |> 
  mutate(year = year(date)) |> 
  group_by(year) |> 
  count(species) |> 
  pivot_wider(names_from = "species",
              values_from = "n",
              values_fill = 0) |> 
  kable(booktabs = T,
        linesep = "",
        caption = "Counts of species encountered during species composition sampling in the lower Dungeness River in 2021-2023.") |> 
  kable_styling(latex_options = c("hold_position"))
```

```{r spp-cnts-date}
sthd_kelts <- 
  spp_comp |> 
  filter(species == "Steelhead",
         str_detect(comments, regex("kelt", ignore_case = T))) |>
  count(mark_status,
        year, date) |> 
  add_column(species = "Steelhead Kelt",
             .before = 0) |> 
  arrange(date,
          mark_status)

spp_catch <-
  spp_comp |> 
  filter((is.na(rmu) | rmu < 6),
         (month(date) <= 6 |
            month(date) == 6 & mday(date) <= 15),
         (is.na(site) | str_detect(site, "Gray Wolf", negate = TRUE))) |>
  mutate(across(mark_status,
                ~ replace_na(.,
                             "UM")),
         across(mark_status,
                ~ case_match(., 
                             "-" ~ "UM",
                             "M?" ~ "UM",
                             .default = .))) |> 
  count(species,
        year, date, mark_status) |> 
  bind_rows(sthd_kelts) |> 
  pivot_wider(names_from = c("species",
                             "mark_status"),
              values_from = "n",
              values_fill = 0,
              names_sep = " (") |>
  select(-contains("No Catch")) |> 
  arrange(date) |> 
  rlang::set_names(function(x) {
      case_when(str_detect(x, "^Bull") |
                str_detect(x, "^Cutthroat") ~ str_remove(x, " \\(UM"),
              str_detect(x, "\\(") ~ paste0(x, ")"),
                .default = x)
  }) |> 
  mutate(across(`Steelhead (AD)`,
                ~ if_else(. > 0, 
                          . - `Steelhead Kelt (AD)`,
                          .)),
         across(`Steelhead (UM)`,
                ~ if_else(. > 0,
                          . - `Steelhead Kelt (UM)`,
                          .)))

spp_catch |> 
  bind_rows(spp_catch |> 
              group_by(year) |> 
              summarize(across(-date,
                               sum))) |> 
  arrange(year, date) |> 
  mutate(across(date,
                ~ format(., "%b %d")),
         across(date,
                ~ replace_na(., "Total"))) |> 
  rename(Year = year,
         Date = date) |> 
  kable(booktabs = T,
        linesep = "",
        # escape = T,
        align = "c",
        longtable = T,
        caption = "Counts of species encountered during species composition sampling in the lower Dungeness River in 2021 - 2023, with steelhead differentiated by mark status (marked (AD) or unmarked (UM)) and kelt status.") |> 
  kable_styling(latex_options = c("repeat_header",
                                  "scale_down",
                                  "hold_position")) |> 
  row_spec(c(sum(spp_catch$year == 2021) + 1,
             sum(spp_catch$year %in% c(2021, 2022)) + 2,
             sum(spp_catch$year %in% c(2021, 2022, 2023)) + 3),
           bold = T,
           hline_after = T) |>
  column_spec(column = c(3:ncol(spp_catch)),
              width = "1.5cm") |> 
  collapse_rows(1)
```

```{r fl-hist, fig.height = 4, fig.cap = "Fork length distributions of fish encountered during species composition sampling in the lower Dungeness River in 2021 - 2023, colored by species."}
spp_fl %>%
  ggplot(aes(x = fork_length_cm,
             fill = species)) +
  geom_histogram(position = "dodge",
                 binwidth = 4) +
  scale_fill_discrete_qualitative(name = "Species") +
  labs(x = "Fork Length (cm)",
       y = "Count")
```

## Determining Species

The impacts of Julian day and fork length on the probability of a fish being a steelhead are displayed in Figure \@ref(fig:spp-pred). Generally, larger fish have a greater chance of being a steelhead, but the exact break point of length (i.e. 50% probability of being a steelhead) shifts over the course of the season. The number of estimated steelhead is shown in Table \@ref(tab:pred-sthd-gam). 

```{r spp-pred, fig.height = 6, fig.cap = "Julian day and fork length of each fish detected on SONAR, 2019-2023, colored by the predicted probability of being a steelhead from the GAM. Size of the point corresponds to the precision of the predicted probability (larger points indicate greater precision). Dark line indicates the 50% probability of being a steelhead. Yellow points indicate observed fish from the species composition sampling that were used in the GAM."}
# what is the fork length when 50% of being a steelhead?
p_pred = 0.5
pred_tab <- crossing(fork_length_cm = seq(35, 90, by = 1),
                     survey_date = seq(ymd(20220201),
                                       ymd(20220615),
                                       by = "1 days")) %>%
  mutate(fl_z = (fork_length_cm - unique(spp_fl$fl_mean)) / unique(spp_fl$fl_sd),
         jday = yday(survey_date)) %>%
  bind_cols(predict(fl_mod,
                    newdata = .,
                    type = "response",
                    se.fit = T) %>%
              as_tibble() %>%
              select(prob_sthd = fit,
                     prob_se = se.fit)) |> 
  rename(plot_date = survey_date)

sonar_pred_spp |>
  filter(month(date) < 6 |
           (month(date) == 6 & day(date) <= 15)) |>
  mutate(plot_date = ymd(20211231) + days(jday)) |>
  ggplot(aes(x = plot_date,
             y = fork_length_cm,
             color = prob_sthd)) +
  geom_point(aes(size = 1/prob_se)) +
  scale_color_continuous_diverging(name = "Probability of Being a Steelhead",
                                   # palette = "Purple-Green",
                                   palette = "Cork",
                                   # palette = "Blue-Red 3",
                                   # palette = "Berlin",
                                   # rev = T,
                                   mid = 0.5,
                                   guide = guide_colorbar(barwidth = 12)) +
  geom_smooth(data = pred_tab %>%
                filter(prob_sthd >= p_pred) %>%
                group_by(plot_date) %>%
                filter(fork_length_cm == min(fork_length_cm)) %>%
                arrange(plot_date, fork_length_cm),
              color = "gray20",
              linetype = 1,
              linewidth = 1.5) +
  geom_point(data = spp_fl |> 
               mutate(plot_date = ymd(20211231) + days(jday),
                      across(species,
                             ~ if_else(. != "Steelhead",
                                       "Not Steelhead",
                                       .))),
             aes(shape = species),
             color = "gray20",
             fill = "gold",
             size = 3) +
  scale_shape_manual(values = c("Steelhead" = 21,
                                "Not Steelhead" = 24),
                     name = "Obs. Species") +
  theme(legend.position = "bottom",
        legend.box="vertical") +
  guides(size = "none") +
  labs(x = "Date",
       y = "Fork Length (cm)") #+
# ggpubr::theme_pubr()
```


```{r pred-sthd-gam-old, eval = F}
sonar_pred_spp |> 
  filter(direction %in% c("upstream",
                          "downstream")) |> 
  mutate(sthd_length = if_else(fork_length_cm >= 67,
                               T, F)) |> 
  group_by(year,
           direction,
           gr_67 = sthd_length) |> 
  summarize(n_fish = n(),
            prob_gr_50 = sum(prob_sthd > 0.5),
            .groups = "drop") |> 
  rowwise() |> 
  mutate(n_sthd = if_else(gr_67, 
                          n_fish,
                          prob_gr_50)) |> 
  group_by(year,
           direction) |> 
  mutate(tot_sthd = sum(n_sthd)) |>
  ungroup() |> 
  pivot_wider(names_from = c(gr_67),
              values_from = c(n_fish:tot_sthd),
              names_vary = "slowest") |>
  select(-tot_sthd_FALSE) |> 
  arrange(desc(direction),
          year) |> 
  relocate(direction,
           .before = "year") |> 
  mutate(across(direction,
                ~ str_to_title(.))) |> 
  kable(col.names = c("Direction",
                      "Year",
                      c(rep(c("n Fish",
                              "Likely Sthd",
                              "Est. Sthd"),
                            2),
                        "Total Sthd")),
        booktabs = T,
        linesep = "",
        caption = "Number of fish observed moving downstream or upstream from SONAR (n Fish), separated by fish less than or greater than 67 cm, and whether they were likely (> 50% probability) to be a steelhead according to the species composition GAM (Likely Sthd). Estimated steelhead within each movement and size group (Est. Sthd) are summed across size groups to provide the total steelhead for each year by direction (Total Sthd). Note that for fish greater than 67 cm, we assumed they were all steelhead, regardless of the GAM predictions.") |>
  kable_styling(latex_options = c("scale_down",
                                  "hold_position")) |> 
  column_spec(c(9),
              bold = T) |> 
  add_header_above(c("",
                     "",
                     "$\\leq$ 67cm" = 3,
                     "$\\gt$ 67 cm" = 3,
                     ""),
                   escape = F) |> 
  collapse_rows(c(1))
```

```{r pred-sthd-gam}
sonar_pred_spp |> 
  filter(direction %in% c("upstream",
                          "downstream")) |> 
  group_by(year,
           direction) |> 
  summarize(n_fish = n(),
            n_sthd = sum(prob_sthd > 0.5),
            .groups = "drop") |> 
  arrange(desc(direction),
          year) |> 
  relocate(direction,
           .before = "year") |> 
  mutate(across(direction,
                ~ str_to_title(.)),
         across(year,
                as.factor)) |> 
  kable(col.names = c("Direction",
                      "Year",
                      "n Fish",
                      "Est. Steelhead"),
        booktabs = T,
        linesep = "",
        format.args = list(big.mark = ","),
        caption = "Number of fish observed moving upstream or downstream from SONAR (n Fish), and how many were estimated (> 50% probability) to be a steelhead according to the species composition GAM (Est. Steelhead).") |>
  kable_styling(latex_options = c("scale_down",
                                  "hold_position")) |> 
  collapse_rows(c(1))
```

\FloatBarrier

## Abundance Estimation

The estimated marginal effects of various covariates on the expected number of upstream and downstream moving fish are shown in Figures \@ref(fig:up-marg) and \@ref(fig:down-marg) respectively. For both directions, the model indicates that a greater number of steelhead will move during the night, especially in the late evening, compared to the daytime, and more will move when discharge flows are near 600 cfs. There is also a clear effect of day-of-year, with upstream numbers peaking near the beginning of April, while downstream numbers peak near the beginning of May, with some year-to-year variability in that run-timing curve. 

```{r gam-plots}
hr_max = 0.55
disch_max = 0.3
doy_max = 35

up_hr_p <- plot_smooths(up_mod,
                        series = hour_of_day,
                        conditions = quos(prop_hr_sampled == 1),
                        transform = exp) +
  scale_y_continuous(limits = c(NA, hr_max)) +
  labs(x = "Hour of Day",
       y = "Expected Number\nUpstream Fish / 30 min")

up_disch_p <- plot_smooths(up_mod,
                           series = mean_discharge,
                           # comparison = year,
                           conditions = quos(prop_hr_sampled == 1),
                           transform = exp) +
  scale_y_continuous(limits = c(NA, disch_max)) +
  scale_x_continuous(limits = c(NA, max(up_data$mean_discharge, na.rm = T))) +
  labs(x = "Discharge (cfs)",
       y = "Expected Number\nUpstream Fish / 30 min")

up_doy_p <- get_gam_predictions(up_mod,
                                series = day_of_year,
                                series_length = 151,
                                conditions = quos(prop_hr_sampled == 1),
                                exclude_random = F,
                                exclude_terms = s(mean_discharge)) |>
  as_tibble() |>
  mutate(across(day_of_year,
                as.integer),
         date = ymd(20201231) + days(day_of_year)) |>
  mutate(across(c(total_observed_hr,
                  starts_with("CI")),
                exp),
         across(c(total_observed_hr,
                  starts_with("CI")),
                ~ . * 2 * 24)) |>
  filter(month(date) < 6 |
           (month(date) == 6 & day(date) <= 15)) |>
  ggplot(aes(x = date,
             y = total_observed_hr,
             color = year,
             fill = year)) +
  geom_ribbon(aes(ymin = CI_lower,
                  ymax = CI_upper),
              color = NA,
              alpha = 0.2) +
  geom_line() +
  scale_y_continuous(limits = c(NA, doy_max)) +
  scale_x_date(date_labels = "%b%e") +
  scale_colour_discrete_qualitative(name = "Year") +
  scale_fill_discrete_qualitative(name = "Year") +
  labs(x = "Date",
       y = "Expected Number\nUpstream Fish / Day")

marg_up_p <- ggarrange(ggarrange(up_hr_p,
                                 up_disch_p,
                                 labels = c("A", "B"),
                                 nrow = 1),
                       ggarrange(up_doy_p,
                                 labels = "C"),
                       ncol = 1)


down_hr_p <- plot_smooths(down_mod,
                          series = hour_of_day,
                          conditions = quos(prop_hr_sampled == 1),
                          transform = exp) +
  scale_y_continuous(limits = c(NA, hr_max)) +
  labs(x = "Hour of Day",
       y = "Expected Number\nDownstream Fish / 30 min")

down_disch_p <- plot_smooths(down_mod,
                             series = mean_discharge,
                             # comparison = year,
                             conditions = quos(prop_hr_sampled == 1),
                             transform = exp) +
  scale_y_continuous(limits = c(NA, disch_max)) +
  scale_x_continuous(limits = c(NA, max(down_data$mean_discharge, na.rm = T))) +
  labs(x = "Discharge (cfs)",
       y = "Expected Number\nDownstream Fish / 30 min")

down_doy_p <- get_gam_predictions(down_mod,
                                  series = day_of_year,
                                  series_length = 151,
                                  conditions = quos(prop_hr_sampled == 1),
                                  exclude_random = F,
                                  exclude_terms = s(mean_discharge)) |>
  as_tibble() |>
  mutate(across(day_of_year,
                as.integer),
         date = ymd(20201231) + days(day_of_year)) |>
  mutate(across(c(total_observed_hr,
                  starts_with("CI")),
                exp),
         across(c(total_observed_hr,
                  starts_with("CI")),
                ~ . * 2 * 24)) |>
  filter(month(date) < 6 |
           (month(date) == 6 & day(date) <= 15)) |>
  ggplot(aes(x = date,
             y = total_observed_hr,
             color = year,
             fill = year)) +
  geom_ribbon(aes(ymin = CI_lower,
                  ymax = CI_upper),
              color = NA,
              alpha = 0.2) +
  geom_line() +
  scale_y_continuous(limits = c(NA, doy_max)) +
  scale_x_date(date_labels = "%b%e") +
  scale_colour_discrete_qualitative(name = "Year") +
  scale_fill_discrete_qualitative(name = "Year") +
  labs(x = "Date",
       y = "Expected Number\nDownstream Fish / Day")

marg_down_p <- ggarrange(ggarrange(down_hr_p,
                                   down_disch_p,
                                   labels = c("A", "B"),
                                   nrow = 1),
                         ggarrange(down_doy_p,
                                   labels = "C"),
                         ncol = 1)


```

Estimates of early (February 1 - May 15, upstream - downstream), late (May 16 - June 16, upstream only), and total annual escapement of winter steelhead are shown in Table \@ref(tab:year-tab). The proportions of kelts, measured as the number of downstream moving steelhead counted after May 15 divided by the total annual escapement, are shown in Table \@ref(tab:kelt-prop). 

```{r year-tab}
yr_est |> 
  select(year,
         group,
         estimate = median,
         se,
         low_ci = `2.5%`,
         upp_ci = `97.5%`) |> 
  pivot_wider(names_from = group,
              values_from = c(estimate:upp_ci),
              names_vary = "slowest") |> 
  mutate(across(year,
                as.factor)) |> 
  kable(col.names = c("Year",
                      rep(c("Estimate",
                            "SE",
                            "Low CI",
                            "Upp CI"),
                          3)),
        digits = c(0,
                   rep(c(0, 1,
                         0, 0),
                       3)),
        format.args = list(big.mark = ","),
        booktabs = T,
        linesep = "",
        caption = "Annual estimates of winter steelhead escapement to the Dungeness River between February 1 and June 15. Early (February 1- May 15), late (May 16 – June 15), total escapement estimate, standard error and range of the 95% confidence interval (CI).") |> 
  kable_styling(latex_options = c("scale_down",
                                  "hold_position")) |> 
  column_spec(c(2, 6, 10),
              bold = T) |> 
  add_header_above(c("",
                     "Early (Feb 1 - May 15)" = 4,
                     "Late (May 16 - June 15)" = 4,
                     "Total" = 4))
```

```{r year-tab-simple, eval = F}
yr_est |>
  filter(group == "total") |> 
  select(year,
         estimate = median,
         se,
         low_ci = `2.5%`,
         upp_ci = `97.5%`) |> 
  kable(col.names = c("Year",
                      "Estimate",
                      "SE",
                      "Low CI",
                      "Upp CI"),
        digits = c(0, 0,
                   1, 0, 0),
        format.args = list(big.mark = ","),
        booktabs = T,
        linesep = "",
        caption = "Annual estimates of net escapemet of winter steelhead to the Dungeness River between February 1 and June 15.") |> 
  kable_styling(latex_options = c("scale_down",
                                  "hold_position"))
```

```{r kelt-prop}
# calculate proportion of total escapement that were detected as kelts
yr_draws |>
  left_join(yr_draws_kelts,
            by = join_by(year, draw)) |> 
  mutate(kelt_prop = kelts / total) |> 
  group_by(year) |> 
  summarize(across(c(total,
                     kelts,
                     kelt_prop),
                   list(mean = ~ mean(.),
                        median = ~ median(.),
                        se = ~ sd(.))),
            .groups = "drop") |> 
  mutate(cv = kelt_prop_se / kelt_prop_mean) |>
  select(year,
         total = total_median,
         kelts = kelts_median,
         kelt_proportion = kelt_prop_median,
         se = kelt_prop_se) |> 
  clean_names("title") |> 
  rename(SE = Se) |> 
  kable(booktabs = T,
        linesep = "",
        digits = c(0,0,0,
                   3,3),
        caption = "Proportion of kelts estimated each year, with standard error.") |>
  kable_styling(latex_options = c("hold_position"))

```


```{r up-marg, fig.height = 6, fig.cap = "Marginal effects for upstream-moving fish as estimated by the GAM for hour of day (A), discharge (B), and Julian day of year (C). Shaded areas indicated 95% confidence intervals."}
marg_up_p
```

```{r down-marg, fig.height = 6, fig.cap = "Marginal effects for downstream-moving fish as estimated by the GAM for hour of day (A), discharge (B), and Julian day of year (C). Shaded areas indicated 95% confidence intervals."}
marg_down_p
```

\FloatBarrier

### Comparison with Redd-Based Estimates

Comparisons between redd-based estimates and SONAR-based estimates can be seen in Table \@ref(tab:redd-tab) and Figure \@ref(fig:redd-fig). In the `r english(n_distinct(comp_est$year[!is.na(comp_est$redd_est)]))` years with comparable estimates, SONAR-based estimates were significantly higher than redd-based estimates each year. The redd-based estimates did not fall within the 95% confidence intervals of the SONAR-based estimates, but they were consistently about half of the SONAR-based estimates (`r paste(round(range(comp_est$redd_est / comp_est$median, na.rm = T), 3) * 100, collapse = " - ")`%).

```{r redd-tab}
comp_est |> 
  select(year,
         redd_est,
         median,
         se:`97.5%`) |> 
  kable(col.names = c("Year",
                      "Redd Est.",
                      "SONAR Est.",
                      "SE",
                      "Low CI",
                      "Upp CI"),
        digits = c(0, 0, 0,
                   1, 0, 0),
        format.args = list(big.mark = ","),
        booktabs = T,
        linesep = "",
        caption = "Annual estimates of winter steelhead escapement to the Dungeness River based on redd counts and SONAR (with 95% confidence intervals and standard error (SE))") |> 
  kable_styling(latex_options = c("hold_position"))
```

```{r redd-fig, fig.cap = "Annual estimates of winter steelhead escapement to the Dungeness River, based on SONAR (with 95% confidence intervals) and redd counts."}
pd = 0.2
comp_est |>
  ggplot(aes(x = year)) +
  geom_errorbar(aes(ymin = `2.5%`,
                    ymax = `97.5%`,
                    color = "SONAR"),
                width = 0.1) +
  geom_point(aes(y = median,
                 color = "SONAR"),
             size = 4) +
  # geom_point(aes(y = n_fish,
  #                color = "Counts\nof Sthd.\n(SONAR)"),
  #            size = 4,
  #            position = position_jitter(width = pd)) +
  geom_point(aes(y = redd_est,
                 color = "Redd\nsurveys"),
             size = 4,
             position = position_jitter(width = pd)) +
  scale_color_discrete_qualitative(palette = "Dark 3",
                                   name = "Data\nSource") +
  labs(x = "Year",
       y = "Total Upstream Escapement")
```

\FloatBarrier
\newpage

# Discussion

We used SONAR to make annual estimates of winter steelhead escapement on the Dungeness River for spawn years 2019 - 2023. To do so, we needed to collect and utilize independent species composition data, and develop an analysis technique that allowed us to estimate passage during periods when the SONAR was not operable or the video had not been reviewed. Analyzing these initial years of data has prompted several observations worth mentioning.

First, SONAR location  is a crucial component of a successful SONAR project. In 2018 we observed frequent milling behavior at the SONAR site, and upstream and downstream fish counts were high, presumably due to milling. As a result, only 29% of the season was reviewed (Figures \@ref(fig:op-fig) and \@ref(fig:review-fig) and Table \@ref(tab:pct-ops)). We decided to treat 2018 as a pilot year and we did not make a SONAR-based escapement estimate. Instead, we utilized the lessons learned from that year to improve operations in subsequent years. After observing the fish behavior at the initial location in 2018, we moved the SONAR to a habitat unit that was more of a run, and more conducive to fish actively migrating through rather than milling around. In 2019 – 2022 we observed a much lower number of fish moving in each half-hour period compared to 2018 (Figures \@ref(fig:up-marg) and \@ref(fig:down-marg)). The mean count of upstream moving fish in a half-hour period 2019 – 2022 ranged from 0.16 - 0.26, and the mean count of downstream moving fish ranged from 0.06 – 0.10, compared to a mean of 0.80, and 0.55 in 2018. However, in late 2022 a river restoration project was completed just upstream of the SONAR site and diverted some of the river flow into the newly restored side channel. In 2023 the counts of both upstream and downstream moving fish rose (Figures  \@ref(fig:up-marg) and \@ref(fig:down-marg)) to a mean of 0.43 and 0.29, respectively, and the majority of fish captured during species composition sampling were captured within the pool below the restoration site, presumably due to fish milling below the new channel. Despite the higher fish counts in 2023, the overall escapement was comparable to the other years we analyzed. Preliminary results for 2024 indicate that the river has scoured out the new side channel and fish are no longer holding or milling to the degree they were in 2023 (K. Sutton, WDFW, pers. comm).

In addition to fish behavior at the site, access and security are important considerations. After we moved the SONAR site slightly upstream in 2019 and deployed the unit from a fixed platform on the bank, it was much easier for the team to check on and make adjustments to the unit. The 2019-2023 site is also located on WDFW property, enabling a direct power source, and an on-site staff trailer for security and comfort in bad weather.

```{r mean-counts, eval = F, echo = F}
ts_obs_all |> 
  filter(reviewed) |> 
  group_by(direction, year) |> 
  summarize(across(n_fish, mean),
            .groups = "drop") |> 
  mutate(across(n_fish,
                ~ round_half_up(., digits = 2))) |> 
  pivot_wider(names_from = "direction",
              values_from = "n_fish") |> 
  arrange(up)
```


Second, the variability between observers was relatively small. The total counts between pairs of observers each year were very similar, especially for upstream moving fish (Table \@ref(tab:obs-totals)). The coefficient of variation among different observers' length measurements was quite small, suggesting good consistency across observers. It should be noted that we matched up which fish each observer measured in such a way as to minimize observer-to-observer differences for multiple fish observed in the same half-hour period. The overall bias in measurements, compared to observer AS, was quite low, but not zero. This could have an impact on whether a fish is predicted to be a steelhead or not, since length is a determining covariate in the species prediction model. However, Figure \@ref(fig:lgth-comp-fig) suggests that there are differences in length measurements in both the positive and negative direction, so the impact on steelhead counts should be minimal.

Third, how to best deal with steelhead kelts is an open question. For fish that move upstream, downstream, and upstream again before spawning, we would like to subtract the downstream counts from the upstream counts, to avoid double-counting the same fish. However, steelhead that kelt may be observed moving upstream and again moving downstream, and we do not want those counts to cancel each other out. Currently, we are sidestepping this issue by assuming that the number of kelts detected prior to `r down_date` is equal to the number of downstream milling detections after that date. However, that date is at best an educated guess which could lead to bias in our estimates in one direction or the other. Continued investigation of this issue is warranted, perhaps by more closely examining the species composition data for kelting behavior (or changing the species composition sampling to better target kelts) or by analyzing metrics such as the upstream:downstream count ratios through the season, to determine if there is a pattern that could guide what that equilibrium date should be.

In an effort to better understand the timing of kelt movement, in 2024 we started a project to acoustically tag a sample of upstream moving steelhead. Using existing acoustic receivers positioned throughout the Dungeness watershed, we hope to learn when kelts are likely to be passing the SONAR moving downstream, and whether the timing of when kelts are detected is related to the timing of when they initially pass the SONAR while migrating upstream. This information should help better inform the choice of a date to separate downstream milling versus kelting behavior, or provide data to improve the approach to analyzing kelts. 

Finally, the species composition data raised a few issues for future consideration. A few bull trout were captured multiple times in the same pool during species composition netting, suggesting that the species composition sampling may be sampling not just fish that are moving, but also fish that may be holding (i.e. not moving past the SONAR). Whether this actually impacts the predictions of species based on size and Julian day is unclear. To better identify holding fish, in 2024 we are tagging all bull trout and steelhead (that aren’t acoustic tagged) with individually numbered FLOY tags. In addition, the current species composition methods cannot account for potential differences in what hour of the day certain species are more or less likely to move. If steelhead are more likely to move at night, as suggested by the hour of day co-variate in our model, compared to other species, we would want to incorporate hour of day into our species prediction. Without a different study design for species composition, we are unable to address this question. However, it seems reasonable to assume that steelhead and bull trout have similar behavior with regards to movement and time of day. With regard to steelhead origin, `r paste(round(range(phos_calc$phos), 3) * 100, collapse = " - ")`% of the steelhead caught each year during species composition sampling were hatchery-origin. We did not distinguish between natural-origin and hatchery-origin steelhead in our abundance estimates, but in future years we could consider estimating pHOS. 

The SONAR-based estimates of steelhead escapement were significantly greater than redd-based estimates for the `r english(n_distinct(comp_est$year[!is.na(comp_est$redd_est)]))` years we could make comparisons. Although the two estimates are focused on slightly different life-stages (SONAR-based estimates are focused on pre-spawn steelhead, while redd-based estimates focus on spawners), and some steelhead may experience pre-spawn mortality, we would not expect that to explain the large differences between the two estimates. We hypothesize that the redd-based estimate could be biased low because steelhead redds are difficult to see, and often observed imperfectly [@Murdoch2018], leading to an under-count of redds. In addition, perhaps not all of steelhead spawning habitat was surveyed for redds. In fact, the Grey Wolf River and upper Dungeness are difficult to access, and due to their high gradients, must be surveyed at lower flows than the lower basin, resulting in few surveys per season, and the potential to miss redds. Another reason for redd-based estimates to be biased low could be because the fish / redd number used, 1.62, is too low. Finally, the year that redd expansions are based on, 2015, was an abnormally low water year, and may not reflect spawn timing in average water years. Alternatively, the SONAR-based estimate could be biased high if the date we chose to stop subtracting downstream moving fish was too early, or if our species composition model identified too many non-steelhead fish as steelhead. It should be noted that the SONAR-based estimates tracked the redd-based estimates fairly consistently (redd-based estimates were on average `r round(mean(comp_est$redd_est / comp_est$median, na.rm = T), 3) * 100` % of the SONAR-based estimates), suggesting a consistent bias between the two. 

## Recommendations

In the future, we recommend setting the SONAR unit up earlier in the year, before the steelhead start moving upstream into the Dungeness River. Even in 2021, when the SONAR was deployed starting February 1, there was still one steelhead detected on that date, suggesting the run may begin sooner than that. If the SONAR is deployed earlier, then we would also recommend that the species composition sampling begin at the same point in the year that the SONAR is deployed, to ensure that we can identify when steelhead (as opposed to other species) are moving in the Dungeness. In 2024 we deployed the SONAR in late December, and we began the species composition sampling in January. After a few years of deploying earlier, we may be able to move the deployment date later based on our better understanding of when the run starts.

We also recommend investigating the use of image recognition software and machine learning processing to help automate the review of SONAR images. Technicians are required to spend a substantial amount of time reviewing SONAR video, and if that could be reduced it would have multiple benefits. First, cutting hours of tedious review time could potentially be cost-effective, and make the data available for analysis sooner. Second, it would make the counts more reproducible and less subject to an individual observer's skill and experience. Finally, by automating the review process there would no longer be a need to selectively choose which periods to review (e.g., first 30 minutes of every hour). Instead, counts could be obtained for the entire period the SONAR is deployed, reducing the reliance on estimates for periods with missing data. 

Additionally, we recommend considering study design changes to the species composition sampling to answer the questions we have with these data. We could consider constraining the species composition sampling closer to the SONAR site to attempt to capture only fish actively migrating, and not fish that are holding. We could also consider modifying the species composition sampling to attempt to estimate pHOS in different parts of the river. We also recommend testing whether time of day affects the species composition by doing some sampling sets in the late afternoon and evening, or possibly some snorkel counts during the day and night. 

# Acknowledgements

Andrew Simmons, Dan Gorze, Jayson Gallatin, Brent Trim, Greg Boecker, and Jake Eastby of WDFW operated, maintained, and reviewed SONAR imagery data. Calvin Stokes, Alec Bauer, and Bethany Craig also reviewed SONAR imagery. Keith Denton provided guidance and consultation on SONAR deployment and operation. Peter Topping provided project support and advice. Kathryn Sutton led weekly species composition sampling with the help of many staff including Calvin Stokes, Trevor Allen, Jenni Whitney, Scott Williams, Jeff Gufler, David Thomas, Jacob Portney, Caleb Owen, and Kayla Own of WDFW, Chris Burns, Jarrett Burns, Casey Allen, and Aaron Brooks of the Jamestown S’Klallam Tribe, Dave Shreffler of Shreffler and Associates, Keith Denton of Keith Denton and Associates, and Roger Peters, Roger Tabor, Greg Byford, Evan Lewis, Jakob Bengelink, and Jack Brill of the U.S. Fish and Wildlife Service.

# Literature Cited

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->
<div id="refs"></div>

